{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e20e555",
   "metadata": {},
   "source": [
    "Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33b3149a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import r2_score\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import torchmetrics\n",
    "from pytorch_tabular import TabularModel\n",
    "from ff_utils import FeedForward, test_model, MyDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b52bcc-3d3a-41ce-804c-9e47b80ff37b",
   "metadata": {},
   "source": [
    "Implementazione API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c84f7995-2940-4aa3-845a-0575a91d2e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output: unique ID of the team\n",
    "def getName():\n",
    "    return \"RACITI GABRIELE\"\n",
    "\n",
    "# Input: Test dataframe\n",
    "# Output: PreProcessed test dataframe\n",
    "def preprocess(df, clfName):\n",
    "    if clfName.lower() == \"lr\":\n",
    "        X = df.drop(columns=['Year'])\n",
    "        y = df['Year']\n",
    "        scaler = pickle.load(open(\"./models/standardization.save\", 'rb'))\n",
    "        X = pd.DataFrame(scaler.transform(X))\n",
    "        norm = pickle.load(open(\"./models/normalizer_l2.save\", 'rb'))\n",
    "        X = pd.DataFrame(norm.transform(X))\n",
    "        dfNew = pd.concat([y, X], axis = 1)\n",
    "        return dfNew\n",
    "    elif clfName.lower() == \"knr\":\n",
    "        X = df.drop(columns=['Year'])\n",
    "        y = df['Year']\n",
    "        scaler = pickle.load(open(\"./models/minmax_scaler.save\", 'rb'))\n",
    "        X = pd.DataFrame(scaler.transform(X))\n",
    "        pca = pickle.load(open(\"./models/pca70minmax.save\", 'rb'))\n",
    "        X = pd.DataFrame(pca.transform(X))\n",
    "        dfNew = pd.concat([y, X], axis = 1)\n",
    "        return dfNew\n",
    "    elif clfName.lower() ==\"svr\":\n",
    "        X = df.drop(columns=['Year'])\n",
    "        y = df['Year']\n",
    "        scaler = pickle.load(open(\"./models/minmax_scaler.save\", 'rb'))\n",
    "        X = pd.DataFrame(scaler.transform(X))\n",
    "        dfNew = pd.concat([y, X], axis = 1)\n",
    "        return dfNew\n",
    "    elif clfName.lower() ==\"rf\":\n",
    "        X = df.drop(columns=['Year'])\n",
    "        y = df['Year']\n",
    "        scaler = pickle.load(open(\"./models/minmax_scaler.save\", 'rb'))\n",
    "        X = pd.DataFrame(scaler.transform(X))\n",
    "        pca = pickle.load(open(\"./models/pca30minmax.save\", 'rb'))\n",
    "        X = pd.DataFrame(pca.transform(X))\n",
    "        dfNew = pd.concat([y, X], axis = 1)\n",
    "        return dfNew\n",
    "    elif clfName.lower() ==\"ff\":\n",
    "        X = df.drop(columns=['Year'])\n",
    "        y = df['Year']\n",
    "        scaler = pickle.load(open(\"./models/minmax_scaler.save\", 'rb'))\n",
    "        X = pd.DataFrame(scaler.transform(X))\n",
    "        dfNew = pd.concat([y, X], axis = 1)\n",
    "        return dfNew\n",
    "    elif clfName.lower() ==\"tb\":\n",
    "        X = df.drop(columns=['Year'])\n",
    "        y = df['Year']\n",
    "        scaler = pickle.load(open(\"./models/standardization.save\", 'rb'))\n",
    "        X_scaled = scaler.transform(X)\n",
    "        X_scaled = pd.DataFrame(X_scaled, columns=X.columns) \n",
    "        dfNew = pd.concat([y, X_scaled], axis=1)\n",
    "        return dfNew\n",
    "    elif clfName.lower() ==\"tf\":\n",
    "        X = df.drop(columns=['Year'])\n",
    "        y = df['Year']\n",
    "        scaler = pickle.load(open(\"./models/standardization.save\", 'rb'))\n",
    "        X_scaled = scaler.transform(X)\n",
    "        X_scaled = pd.DataFrame(X_scaled, columns=X.columns) \n",
    "        dfNew = pd.concat([y, X_scaled], axis=1)\n",
    "        return dfNew\n",
    "    \n",
    "    \n",
    "          \n",
    "\n",
    "\n",
    "# Input: Regressor name (\"lr\": Linear Regression, \"SVR\": Support Vector Regressor, ...)\n",
    "# Output: Regressor object\n",
    "def load(clfName):\n",
    "    if (clfName.lower() == \"lr\"):\n",
    "        clf = pickle.load(open(\"./models/linearRegression.save\", 'rb'))\n",
    "        return clf\n",
    "    elif (clfName.lower() == \"svr\"):\n",
    "        clf = pickle.load(open(\"./models/svr.save\", 'rb'))\n",
    "        return clf\n",
    "    elif (clfName.lower() == \"knr\"):\n",
    "        clf = pickle.load(open(\"./models/knn.save\", 'rb'))\n",
    "        return clf\n",
    "    elif (clfName == \"rf\"):\n",
    "        clf = pickle.load(open(\"./models/randomForest.save\", 'rb'))\n",
    "        return clf\n",
    "    elif (clfName.lower() == \"ff\"):\n",
    "        model = FeedForward(90, 128, 1)\n",
    "        model.load_state_dict(torch.load('./models/ff.pth'))\n",
    "        return model \n",
    "    elif (clfName.lower() == \"tb\"):\n",
    "        model = TabularModel.load_model('./models/tabnet', map_location=torch.device('cpu'))\n",
    "        return model\n",
    "    elif (clfName.lower() == \"tf\"):\n",
    "        model = TabularModel.load_model('./models/tabtransformer', map_location=torch.device('cpu'))\n",
    "        return model\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "# Input: PreProcessed dataset, Regressor Name, Regressor Object \n",
    "# Output: Performance dictionary\n",
    "def predict(df, clfName, clf):\n",
    "    X = df.drop(columns=['Year'])\n",
    "    y = df['Year']\n",
    "    if clfName.lower() ==\"ff\":\n",
    "        # device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        device = 'cpu'\n",
    "        X = X.values\n",
    "        y = y.values\n",
    "        test_dataset = MyDataset(X,y)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=1)\n",
    "        clf.to(device)\n",
    "        labels, ypred = test_model(clf, test_loader, device)\n",
    "        \n",
    "        mse_metric = torchmetrics.MeanSquaredError().to(device)\n",
    "        mae_metric = torchmetrics.MeanAbsoluteError().to(device)\n",
    "        mape_metric = torchmetrics.MeanAbsolutePercentageError().to(device)\n",
    "        r2_metric = torchmetrics.R2Score().to(device)\n",
    "\n",
    "        mse = mse_metric(ypred, labels).item()\n",
    "        mae = mae_metric(ypred, labels).item()\n",
    "        mape = mape_metric(ypred, labels).item()\n",
    "        r2 = r2_metric(ypred, labels).item()\n",
    "    elif clfName.lower() ==\"tb\":\n",
    "        ypred = clf.predict(X)\n",
    "        mse = mean_squared_error(y, ypred)\n",
    "        mae = mean_absolute_error(y, ypred)\n",
    "        mape = mean_absolute_percentage_error(y, ypred)\n",
    "        r2 = r2_score(y, ypred)\n",
    "    elif clfName.lower() ==\"tf\":\n",
    "        ypred = clf.predict(X)\n",
    "        mse = mean_squared_error(y, ypred)\n",
    "        mae = mean_absolute_error(y, ypred)\n",
    "        mape = mean_absolute_percentage_error(y, ypred)\n",
    "        r2 = r2_score(y, ypred)\n",
    "    else:\n",
    "        ypred = clf.predict(X)\n",
    "        mse = mean_squared_error(y, ypred)\n",
    "        mae = mean_absolute_error(y, ypred)\n",
    "        mape = mean_absolute_percentage_error(y, ypred)\n",
    "        r2 = r2_score(y, ypred)\n",
    "    perf = {\"mse\": mse, \"mae\": mae, \"mape\": mape, \"r2score\": r2}\n",
    "    return perf\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef57a17-fca4-4526-bceb-b914800c0c51",
   "metadata": {},
   "source": [
    "Esempio esecuzione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0788ee81-2988-42e1-9251-eb643d2a42ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULT team: RACITI GABRIELE algoName: lr perf: {'mse': 77.12388430135948, 'mae': 6.30986623368177, 'mape': 0.003166652333647582, 'r2score': 0.2835460075656998}\n",
      "RESULT team: RACITI GABRIELE algoName: knr perf: {'mse': 74.40238744606964, 'mae': 6.269314179420018, 'mape': 0.0031452430798335, 'r2score': 0.30882776437855564}\n",
      "RESULT team: RACITI GABRIELE algoName: rf perf: {'mse': 76.3739501528225, 'mae': 6.252239817342722, 'mape': 0.0031378714564361267, 'r2score': 0.290512634307199}\n",
      "RESULT team: RACITI GABRIELE algoName: ff perf: {'mse': 68.86982727050781, 'mae': 5.730935573577881, 'mape': 0.0028767965268343687, 'r2score': 0.3596232533454895}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">11:42:38</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">094</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">165</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m07\u001b[0m-\u001b[1;36m02\u001b[0m \u001b[1;92m11:42:38\u001b[0m,\u001b[1;36m094\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m165\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">11:42:38</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">113</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">340</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m07\u001b[0m-\u001b[1;36m02\u001b[0m \u001b[1;92m11:42:38\u001b[0m,\u001b[1;36m113\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m340\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULT team: RACITI GABRIELE algoName: tb perf: {'mse': 68.62740126952995, 'mae': 5.7732044175034956, 'mape': 0.002898104313781601, 'r2score': 0.36247537224886894}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">11:42:41</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">097</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">165</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m07\u001b[0m-\u001b[1;36m02\u001b[0m \u001b[1;92m11:42:41\u001b[0m,\u001b[1;36m097\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m165\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">11:42:41</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">097</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">340</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m07\u001b[0m-\u001b[1;36m02\u001b[0m \u001b[1;92m11:42:41\u001b[0m,\u001b[1;36m097\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m340\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULT team: RACITI GABRIELE algoName: tf perf: {'mse': 82.50808369580339, 'mae': 6.573350120450326, 'mape': 0.0032990011221899654, 'r2score': 0.23352867263559574}\n",
      "RESULT team: RACITI GABRIELE algoName: svr perf: {'mse': 70.41183485052065, 'mae': 5.53360882747824, 'mape': 0.0027802649616192458, 'r2score': 0.34589860650482196}\n"
     ]
    }
   ],
   "source": [
    "# \"N.B.: E' preferibile inserire le predizioni riguardanti il modello SVR per ultime a causa della lentezza di predizione dovuta alla complessità \n",
    "# del modello (circa 20 minuti per 25mila campioni sulla mia macchina). La scelta di non rendere il modello meno complesso per velocizzare le \n",
    "# predizioni è stata fatta per massimizzare i risultati del modello. In scenari reali, si potrebbe preferire una via di mezzo o utilizzare\n",
    "#  modelli più veloci e performanti.\n",
    "\n",
    "FILENAME = \"test_data.csv\"\n",
    "CLF_NAME_LIST = [\"lr\", \"knr\", \"rf\", \"ff\", \"tb\", \"tf\", \"svr\"]\n",
    "df = pd.read_csv(FILENAME)\n",
    "\n",
    "#Esecuzione degli algoritmi\n",
    "for modelName in CLF_NAME_LIST:\n",
    "    dfProcessed = preprocess(df, modelName)\n",
    "    clf = load(modelName)\n",
    "    perf = predict(dfProcessed, modelName, clf)\n",
    "    print(\"RESULT team: \"+str(getName())+\" algoName: \"+ modelName + \" perf: \"+ str(perf))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
